# ğŸ—‘ï¸ Neovision - Classification des DÃ©chets avec l'IA

## ğŸ“– PrÃ©sentation du Projet
Lâ€™augmentation des dÃ©chets et les dÃ©fis liÃ©s au recyclage nÃ©cessitent des solutions innovantes. Ce projet repose sur **lâ€™intelligence artificielle** et les **rÃ©seaux de neurones convolutifs (CNN)** pour **classer automatiquement les dÃ©chets** Ã  partir dâ€™images.

ğŸ“Œ **Objectif** : DÃ©velopper un modÃ¨le IA permettant de **classifier les dÃ©chets** en plusieurs catÃ©gories avec **85 % de prÃ©cision** et un **temps dâ€™infÃ©rence optimal**.

## ğŸš€ FonctionnalitÃ©s ClÃ©s
âœ… **Classification automatique des dÃ©chets** grÃ¢ce Ã  un modÃ¨le CNN  
âœ… **85% de prÃ©cision** sur les donnÃ©es de test  
âœ… **Temps dâ€™infÃ©rence rapide** 
âœ… **Techniques avancÃ©es de Data Augmentation** pour amÃ©liorer les performances  
âœ… **Utilisation de TensorFlow et Keras** pour lâ€™entraÃ®nement du modÃ¨le  

## ğŸ“‚ Contenu du DÃ©pÃ´t
- `Tri_Intelligent_IA.ipynb` : Notebook principal contenant tout le code du projet


## ğŸ“Š PrÃ©traitement des DonnÃ©es
Les donnÃ©es doivent Ãªtre fournies par l'utilisateur et chargÃ©es dans le notebook.  
Le modÃ¨le est conÃ§u pour fonctionner avec un jeu de donnÃ©es structurÃ© en images et labels.

## ğŸ”„ Augmentation et PrÃ©paration des DonnÃ©es
Pour amÃ©liorer les performances du modÃ¨le, diffÃ©rentes techniques dâ€™augmentation des donnÃ©es sont appliquÃ©es :
- **Rotation alÃ©atoire** des images.
- **Inversion horizontale et verticale**.
- **Ajustement de la luminositÃ©**.
- **Translation et dÃ©calage des images**.
- **Redimensionnement des images en 64x64**.
- **Normalisation des valeurs des pixels**.

Chaque catÃ©gorie de dÃ©chets est augmentÃ©e de maniÃ¨re dynamique afin dâ€™Ã©quilibrer le dataset et Ã©viter le surapprentissage.

## ğŸ—ï¸ Construction du ModÃ¨le CNN
Le modÃ¨le est construit avec plusieurs couches convolutives :
- **4 couches de convolution** avec **filtres 3x3**, activation **ReLU**, suivies de **MaxPooling 2x2**.
- **Batch Normalization** et **Dropout (0.25)** pour Ã©viter le surapprentissage.
- **Une couche Flatten** pour transformer les caractÃ©ristiques en vecteur avant la classification.
- **Une couche Dense de 512 neurones** avec activation ReLU.
- **Dropout (0.5)** aprÃ¨s la couche Dense pour amÃ©liorer la gÃ©nÃ©ralisation.
- **19 classes de sortie** avec activation **softmax**.

Lâ€™optimisation du modÃ¨le est rÃ©alisÃ©e avec :
- **Fonction de perte** : categorical cross-entropy.
- **Optimiseur** : Adam avec un taux dâ€™apprentissage de **0.001**.
- **50 Ã©poques dâ€™entraÃ®nement** avec batch de **250 images**.
- 

## ğŸ“Š Ã‰valuation et RÃ©sultats
- **AmÃ©lioration progressive de la prÃ©cision** au fil des Ã©poques.
- **Validation Loss :**
  - Diminue de **3.79** Ã  **0.43** au fil des Ã©poques.
- **Test Accuracy finale** : **87.3%**
- **Exemple de prÃ©diction rÃ©ussie** sur une image testÃ©e en temps rÃ©el.

## ğŸ›  Technologies UtilisÃ©es
- **Python** (TensorFlow, Keras, OpenCV, Matplotlib, Scikit-learn)
- **Deep Learning** (CNN, Data Augmentation)
- **Jupyter Notebook** pour lâ€™expÃ©rimentation

## ğŸ“§ Contact
Si vous avez des questions ou suggestions, nâ€™hÃ©sitez pas Ã  me contacter via mon profil GitHub.
